{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1406c82d",
   "metadata": {},
   "source": [
    "# Word Embedding (word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d9f2f",
   "metadata": {},
   "source": [
    "As the name implies, _word vectors_ are vectors used to represent words, and can also be considered as feature vectors or representations of words. The technique of mapping words to real vectors is called _word embedding_. In recent years, word embedding has gradually become the basic knowledge of natural language processing.\n",
    "\n",
    "## One-Hot Vectors Are a Bad Choice\n",
    "\n",
    "Although one-hot word vectors are easy to construct, they are usually not a good choice. A main reason is that one-hot word vectors __cannot accurately express the similarity between different words, such as the _cosine similarity_ that is often used in NLP.__ \n",
    "\n",
    "__Cosine Similarity__: is a metric used to measure how similar the documents are irrespective of their size.\n",
    "\n",
    "## Self-Supervised word2vec\n",
    "\n",
    "It was proposed to address the above issue. It maps each word to a fixed-length vector, and these vectors can better express the similarity and analogy relationship among different words. The word2vec contains two models: \n",
    "\n",
    "1. skip-gram\n",
    "2. continuous bag of words (CBOW)\n",
    "\n",
    "For semantically meaningful representations, their training relies on conditional probabilities that can be viewed as predicting some words using some of their surrounding words in corpora. Since supervision comes from the data without labels, both skip-gram and continuous bag of words are self-supervised models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
