{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1599ce",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6999e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d0689",
   "metadata": {},
   "source": [
    "Linear regression stems from a very simple assumption. We assume that the relationship between the features and the target value is approximately linear. \n",
    "\n",
    "At the heart of every solution is a model that descrives how features can be transformed into an estimate of the target. \n",
    "\n",
    "The assumption of linearity means that the expected value of the target(price) can be expressed as a weighted sum of the features(area and age). The weights determine the influence of each feature on our prediction. The bias determines the value of the estimate when all features are zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145272e9",
   "metadata": {},
   "source": [
    "Given a dataset, our goal is to choose the weights w and the bias b that, on average, make our model's predictions fit the true prices observed in the data as closely as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a06db",
   "metadata": {},
   "source": [
    "#### Note: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80139899",
   "metadata": {},
   "source": [
    "Before we can go about seach for the best parameters (or model parameters) w and b, we will need two more things: (i) a quality meausure for some given model(loss function); and (ii) a model procedure for updating the model to improve its quality(gradient descent). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817fedc",
   "metadata": {},
   "source": [
    "## 3.1.1.2 Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab513fa",
   "metadata": {},
   "source": [
    "Naturally, fitting our model to the data requires that we agree on some meausre of fitness (or, equivalently, of unfitness). Losss functions quantify the distance between the real and predicted values of the targe. The loss iwll usually be a non-negative number where smaller values are better and perfect prediction incur a loss of 0. For regression problems, the most common loss function is squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a2a28",
   "metadata": {},
   "source": [
    "## 3.1.1.3 Minibatch Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80203f1",
   "metadata": {},
   "source": [
    "Gradient descent: consists of iteratively reducing the error by updating the paraemters in the direction that incrementally lowers the loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467ff29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
