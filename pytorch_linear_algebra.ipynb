{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472498f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c430abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "x + y, x * y, x/y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9097f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.arange(3)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9426b25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a21022e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f175bf1",
   "metadata": {},
   "source": [
    "Matrices are 2nd order tensors. They are tensors with two axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a869de8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9888b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function reshape in module torch:\n",
      "\n",
      "reshape(...)\n",
      "    reshape(input, shape) -> Tensor\n",
      "    \n",
      "    Returns a tensor with the same data and number of elements as :attr:`input`,\n",
      "    but with the specified shape. When possible, the returned tensor will be a view\n",
      "    of :attr:`input`. Otherwise, it will be a copy. Contiguous inputs and inputs\n",
      "    with compatible strides can be reshaped without copying, but you should not\n",
      "    depend on the copying vs. viewing behavior.\n",
      "    \n",
      "    See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "    \n",
      "    A single dimension may be -1, in which case it's inferred from the remaining\n",
      "    dimensions and the number of elements in :attr:`input`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the tensor to be reshaped\n",
      "        shape (tuple of int): the new shape\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.arange(4.)\n",
      "        >>> torch.reshape(a, (2, 2))\n",
      "        tensor([[ 0.,  1.],\n",
      "                [ 2.,  3.]])\n",
      "        >>> b = torch.tensor([[0, 1], [2, 3]])\n",
      "        >>> torch.reshape(b, (-1,))\n",
      "        tensor([ 0,  1,  2,  3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2efbaabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.arange(10)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bb6068d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.reshape(B, (5, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f96820be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5],\n",
       "         [6, 7],\n",
       "         [8, 9]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db6d2f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc1c869f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4, 6, 8],\n",
       "        [1, 3, 5, 7, 9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6599db26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54699",
   "metadata": {},
   "source": [
    "The elementwise product of two matrices is called theri Hadamard product. Below, we spell out the entires of the Hadamard product of two matrices. By the way, it is important that they have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6a32dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c58b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32accfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.arange(6).reshape(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a94d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60442dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape == A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b190cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 4,  9],\n",
       "        [16, 25]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c935d6",
   "metadata": {},
   "source": [
    "The operation above performs the element wise multiplication of the matrices A, and D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1991ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8ec3f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e77a11db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2],\n",
       "        [ 4,  6],\n",
       "        [ 8, 10]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bee72ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "205d5f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab394a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.],\n",
       "        [ 6.,  9.],\n",
       "        [12., 15.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a2a17",
   "metadata": {},
   "source": [
    "Multiplication of a matrix by a scalar. It produces a matrix or a 2th order tensor with the same shape as the orinal one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8b183",
   "metadata": {},
   "source": [
    "## 2.3.6. Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae19dd",
   "metadata": {},
   "source": [
    "Often, we wish to calculate the sum of a tensor's elements. To express the sum of the elements in a vector, there is a simple function for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbef2aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63e9e3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce70e1",
   "metadata": {},
   "source": [
    "for higher oder tensor the rule maintains, here it goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a357dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aeee32be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d9cfa",
   "metadata": {},
   "source": [
    "A related quantity is the mean, also called the average. We calculate the mean by dividing the sum by the toal number of elements. Because computing the mean is so common, it gets a dedicated library functions tht works analogously to sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaf892f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.],\n",
       "        [ 6.,  9.],\n",
       "        [12., 15.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = x * A\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd5c83f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average: summing all the elements in the tensosr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.5000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"This is the average: summing all the elements in the tensosr\")\n",
    "E.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0e435",
   "metadata": {},
   "source": [
    "Number of elements in the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08dbc7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20003cf",
   "metadata": {},
   "source": [
    "## 2.3.8. Dot Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61b738",
   "metadata": {},
   "source": [
    "We can calculate the dot product of two vectors by performing an elementwise multiplication followed by a sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6622b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function dot in module torch:\n",
      "\n",
      "dot(...)\n",
      "    dot(input, other, *, out=None) -> Tensor\n",
      "    \n",
      "    Computes the dot product of two 1D tensors.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "        Unlike NumPy's dot, torch.dot intentionally only supports computing the dot product\n",
      "        of two 1D tensors with the same number of elements.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): first tensor in the dot product, must be 1D.\n",
      "        other (Tensor): second tensor in the dot product, must be 1D.\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
      "        tensor(7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4110bc",
   "metadata": {},
   "source": [
    "# NOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abe244",
   "metadata": {},
   "source": [
    "Dot product is a scalar value, it is also called scalar product. Do not confuse it with matrix multiplication. Dot product is perfomed with 1th order tensors or 1D tensor!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b0ae70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "511c0dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eebf389e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(z,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a39f6",
   "metadata": {},
   "source": [
    "## 2.3.9. Matrix-Vector Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4279a",
   "metadata": {},
   "source": [
    "Matrix-vector products also describe the key calculation involved in computing the outputs of each layer in a neural network given the outputs from the previous layer.\n",
    "\n",
    "To express a matrix-vector product in code, we use the mv function. Note that the column dimension of A (its length along axis 1) must be the same as the dimension of x (its length).\n",
    "\n",
    "PyTorch has a convenience operator @ that can execute both matrix-vector and matrix-matrix products (depending on its arguments). Thus we can write A@x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07d11aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.reshape(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ddd5522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11b5cf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da42119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping tensor A\n"
     ]
    }
   ],
   "source": [
    "print(\"reshaping tensor A\")\n",
    "F = A.reshape(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88bd9698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d4920b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69c26b",
   "metadata": {},
   "source": [
    "Now checking that the shapes match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28ce00c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 14])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(F, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270762da",
   "metadata": {},
   "source": [
    "and now using the @ operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "216bf1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 14])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F@z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc314f0",
   "metadata": {},
   "source": [
    "testing both results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "258e72fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(F, z) == F@z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9ab8f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function mv in module torch:\n",
      "\n",
      "mv(...)\n",
      "    mv(input, vec, *, out=None) -> Tensor\n",
      "    \n",
      "    Performs a matrix-vector product of the matrix :attr:`input` and the vector\n",
      "    :attr:`vec`.\n",
      "    \n",
      "    If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`vec` is a 1-D tensor of\n",
      "    size :math:`m`, :attr:`out` will be 1-D of size :math:`n`.\n",
      "    \n",
      "    .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): matrix to be multiplied\n",
      "        vec (Tensor): vector to be multiplied\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> mat = torch.randn(2, 3)\n",
      "        >>> vec = torch.randn(3)\n",
      "        >>> torch.mv(mat, vec)\n",
      "        tensor([ 1.0404, -0.6361])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ebc3d",
   "metadata": {},
   "source": [
    "## 2.3.10. Matrix-Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed29c6",
   "metadata": {},
   "source": [
    "Matrix-Matrix multiplication is basically the dot product of the ith column in matrix B to the ith row in matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e0c8474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89b9ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = torch.ones(3, 4)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b2794e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the matrix-matrix multiplication using two different methods\n"
     ]
    }
   ],
   "source": [
    "print(\"Now the matrix-matrix multiplication using two different methods\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ce2fe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5fdbdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.,  3.,  3.],\n",
       "        [12., 12., 12., 12.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "46ee200c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.,  3.,  3.],\n",
       "        [12., 12., 12., 12.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33413d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A, G) == A@G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196debd",
   "metadata": {},
   "source": [
    "Interesting note tho, is that the official documentation says that this function torch.mm does not broadcast. And if the result is supposed to be broadcasted then one should use torch.matmul() instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2952bd",
   "metadata": {},
   "source": [
    "## 2.3.11. Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355aad8",
   "metadata": {},
   "source": [
    "A norm is a function that maps a vector to a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a4c5ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4dab9",
   "metadata": {},
   "source": [
    "Note: torch.norm is deprecated and may be removed in a future PyTorch release. Use torch.linalg.norm(), instead, or torch.linalg.vector_norm() when computring vector norms and torch.linalg.matrix_norm() when computing matrix norms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69adb85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones(4, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ccce0",
   "metadata": {},
   "source": [
    "# 22.1. Geometry and Linear Algebraic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3014c6e",
   "metadata": {},
   "source": [
    "Vectors usually have different interpretations, where data examples are column vectors and weights used to form weighted sums are row vectors. However, it can be beneficial to be flexible. Although a single vector's default orientation is a column vector, for any matrix representing a tabular dataset, treating each data example as a row vector in the matrix is more conventional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d341e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
