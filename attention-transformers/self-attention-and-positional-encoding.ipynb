{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af2324e",
   "metadata": {},
   "source": [
    "# Self-Attention and Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2790540",
   "metadata": {},
   "source": [
    "Prior to the introduction of _attention mechanism_, it was common practice in deep learning to use CNNs or RNNs to encode sequences. However, now with attention mechanisms in the scene, imagine feeding a sequence of tokens into an attention mechanism such that at each step, each token has its own query, keys, and values. Here, when computing the value of a token's representation at the next layer, the token can attend (via its query vector) to each other token (matching based on their key vectors). Using the full set of query-key compatibility scores, we can compute, for each token, a representation building the appropriate weighted sum over the other tokens. Because each token is attending to each other token (unlike the case where decoder steps attend to encoder steps), such architectures are typically described as _self-attention_ models, sometimes also referred as _infra-attention_ model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9ded17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff76b12",
   "metadata": {},
   "source": [
    "## Self-Attention\n",
    "\n",
    "Using multi-head attention, the following code snippet computes the self-attention of a tensor with shape (batch size, number of time steps or sequence length in tokens,_d_). The output tensor has the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0398a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_heads = 100, 5\n",
    "attention = d2l.MultiHeadAttention(num_hiddens, num_heads, 0.5)\n",
    "batch_size, num_queries, valid_lens = 2, 4, torch.tensor([3, 2])\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "d2l.check_shape(attention(X, X, X, valid_lens),\n",
    "                (batch_size, num_queries, num_hiddens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
