{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eee9f27",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9710b",
   "metadata": {},
   "source": [
    "The first modern CNN (Krizhevsky et al., 2012), named AlexNet after one of its inventors, Alex Krizhevsky, is largely an evolutionary improvement over LeNet. It achieved excellent performance in the 2012 ImageNet challenge.\n",
    "\n",
    "Interestingly in the lowest layers of the network, the model learned feature extractors that resembled some traditional filters. Higher layers in the network might build upon these representations to represent larger structures, like eyes, noses, blades of grass, and so on. Even higher layers might represent whole objects like people, airplanes, dogs, or frisbees. Ultimately, the final hidden state learns a compact representation of the image that summarizes its contents such that data belonging to different categories can be easily separated.\n",
    "\n",
    "AlexNet (2012) and its precursor LeNet (1995) share many architectural elements. This begs the question: why did it take so long? A key difference is that over the past two decades, the amount of data and computing power available had increased significantly. As such AlexNet was much larger: it was trained on much more data, and on much faster GPUs, compared to the CPUs available in 1995.\n",
    "\n",
    "AlexNet, which employed an 8-layer CNN, won the ImageNet Large Scale Visual Recognition Challenge 2012 by a large margin (Russakovsky et al., 2013). This network showed, for the first time, that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd1689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class AlexNet(d2l.Classifier):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e560801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 59])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 59])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 29])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 29])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 29])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 14])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 14])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 14])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 14])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 6])\n",
      "Flatten output shape:\t torch.Size([1, 7680])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "AlexNet().layer_summary((1, 1, 224, 244))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca28b0c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210781ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(lr=0.01)\n",
    "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
    "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
