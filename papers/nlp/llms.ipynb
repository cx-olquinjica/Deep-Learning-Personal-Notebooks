{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b1d564",
   "metadata": {},
   "source": [
    "# Natural Language Processing: Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da3d79",
   "metadata": {},
   "source": [
    "* [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)\n",
    "    - Overview: In this paper, we take a step back and ask:\n",
    "        How big is too big? What are the possible risks associated with this\n",
    "        technology and what paths are available for mitigating those risks?\n",
    "        We provide recommendations including weighing the environmental and      financial costs first, investing resources into curating and\n",
    "        carefully documenting datasets rather than ingesting everything on\n",
    "        the web, carrying out pre-development exercises evaluating how\n",
    "        the planned approach fits into research and development goals and\n",
    "        supports stakeholder values, and encouraging research directions\n",
    "        beyond ever larger language models.\n",
    "    - Miscellaneous: [Was Homer a stochastic parrot? Meaning in literary texts and LLMs](https://www.lesswrong.com/posts/EREcbR5jiLvdPcSB3/was-homer-a-stochastic-parrot-meaning-in-literary-texts-and)\n",
    "    \n",
    "* [No Language Left Behind: Scaling Human-Centered Machine Translation](https://paperswithcode.com/paper/no-language-left-behind-scaling-human-1)\n",
    "    - Abstract: Driven by the goal of eradicating language barriers on a global scale, machine translation has solidified itself as a key focus of artificial intelligence research today. However, such efforts have coalesced around a small subset of languages, leaving behind the vast majority of mostly low-resource languages. What does it take to break the 200 language barrier while ensuring safe, high quality results, all while keeping ethical considerations in mind? In No Language Left Behind, we took on this challenge by first contextualizing the need for low-resource language translation support through exploratory interviews with native speakers. Then, we created datasets and models aimed at narrowing the performance gap between low and high-resource languages.\n",
    "\n",
    "* [Galactica: A Large Language Model for Science](https://arxiv.org/pdf/2211.09085v1.pdf)\n",
    "    - Abstract: Information overload is a major obstacle to scientific progress. The explosive growth inscientific literature and data has made it ever harder to discover useful insights in a largemass of information. Today scientific knowledge is accessed through search engines, butthey are unable to organize scientific knowledge alone. In this paper we introduce Galactica:a large language model that can store, combine and reason about scientific knowledge. Wetrain on a large scientific corpus of papers, reference material, knowledge bases and manyother sources. We outperform existing models on a range of scientific tasks. \n",
    "    \n",
    "* [Situating Search](https://dl.acm.org/doi/pdf/10.1145/3498366.3505816)\n",
    "    - Abstract: Search systems, like many other applications of machine learning,have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user’s needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.\n",
    "    \n",
    "\n",
    "* [Chain-of-thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "    - Abstract: We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of- thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.\n",
    "\n",
    "* [Reflexion: An Autonomous Agent with Dynamic Memory and Self-Reflection](https://arxiv.org/pdf/2303.11366.pdf)\n",
    "    - Abstract: Recent advancements in decision-making large language model (LLM) agents have demonstrated impressive performance across various benchmarks. However, these state-of-the-art approaches typically necessitate internal model fine-tuning, external model fine-tuning, or policy optimization over a defined state space. Implementing these methods can prove challenging due to the scarcity of high-quality training data or the lack of well-defined state space. Moreover, these agents do not possess certain qualities inherent to human decision-making processes, specifically the ability to learn from mistakes. Self-reflection allows humans to efficiently solve novel problems through a process of trial and error. Building on recent research, we propose Reflexion, an approach that endows an agent with dynamic memory and self-reflection capabilities to enhance its existing reasoning trace and task-specific action choice abilities. To achieve full automation, we introduce a straightforward yet effective heuristic that enables the agent to pinpoint hallucination instances, avoid repetition in action sequences, and, in some environments, construct an inter- nal memory map of the given environment. To assess our approach, we evaluate the agent’s ability to complete decision-making tasks in AlfWorld environments and knowledge-intensive, search-based question-and-answer tasks in HotPotQA environments. We observe success rates of 97% and 51%, respectively, and provide a discussion on the emergent property of self-reflection.\n",
    "\n",
    "\n",
    "* [Self-Instruct: Aligning Language Model with Self Generated Instructions](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "    - Abstract: Large “instruction-tuned” language models (finetuned to respond to instructions) have demonstrated a remarkable ability to gener- alize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruc- tion data that is limited in quantity, diver- sity, and creativity, therefore hindering the generality of the tuned model. We intro- duce SELF-INSTRUCT, a framework for im- proving the instruction-following capabilities of pretrained language models by bootstrap- ping off its own generations. Our pipeline generates instruction, input, and output sam- ples from a language model, then prunes them before using them to finetune the orig- inal model. Applying our method to vanilla GPT3, we demonstrate a 33% absolute im- provement over the original model on SUPER- NATURALINSTRUCTIONS, on par with the per- formance of InstructGPT0011, which is trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT001. SELF-INSTRUCT provides an almost annotation-free method for aligning pre- trained language models with instructions, and we release our large synthetic dataset to facili- tate future studies on instruction tuning2.\n",
    "\n",
    "* [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/pdf/2303.17651.pdf)\n",
    "    - Abstract: Like people, LLMs do not always generate the best text for a given generation problem on their first try (e.g., summaries, answers, explanations). Just as people then refine their text, we introduce SELF-REFINE, a framework for similarly improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an output using an LLM, then allow the same model to provide multi-aspect feedback for its own output; finally, the same model refines its previously generated output given its own feed- back. Unlike earlier work, our iterative refinement framework does not require supervised training data or reinforcement learning, and works with a single LLM. We experiment with 7 diverse tasks, ranging from review rewriting to math reasoning, demonstrating that our approach outperforms direct generation. In all tasks, outputs generated with SELF-REFINE are preferred by humans and by automated metrics over those generated directly with GPT-3.5 and GPT-4, improving on average by absolute ∼20% across tasks.\n",
    "    \n",
    "* [HuggingGPT: Solving AI tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/pdf/2303.17580.pdf)\n",
    "    - Abstract: Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence. While there are abundant AI models avail- able for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a framework that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards advanced artificial intelligence 2.\n",
    "\n",
    "* [GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Iterpretation](https://arxiv.org/pdf/2304.03879.pdf)\n",
    "    - Abstract: Recent advancements in Natural Language Processing (NLP) have led to the development of NLP-based recommender systems that have shown superior performance. However, current models com- monly treat items as mere IDs and adopt discriminative modeling, resulting in limitations of (1) fully leveraging the content informa- tion of items and the language modeling capabilities of NLP models; (2) interpreting user interests to improve relevance and diversity; and (3) adapting practical circumstances such as growing item inventories. To address these limitations, we present GPT4Rec, a novel and flexible generative framework inspired by search engines. It first generates hypothetical \"search queries\" given item titles in a user’s history, and then retrieves items for recommendation by searching these queries. The framework overcomes previous limi- tations by learning both user and item embeddings in the language space. To well-capture user interests with different aspects and granularity for improving relevance and diversity, we propose a multi-query generation technique with beam search. The gener- ated queries naturally serve as interpretable representations of user interests and can be searched to recommend cold-start items. With GPT-2 language model and BM25 search engine, our framework out- performs state-of-the-art methods by 75.7% and 22.2% in Recall@K on two public datasets. Experiments further revealed that multi- query generation with beam search improves both the diversity of retrieved items and the coverage of a user’s multi-interests. The adaptiveness and interpretability of generated queries are discussed with qualitative case studies.\n",
    "\n",
    "* [Chamelon: Plug-and-Play Compositional Reasoning with Large Language Models](https://arxiv.org/pdf/2304.09842.pdf)\n",
    "    - Abstract: Large language models (LLMs) have achieved remarkable progress in various natu- ral language processing tasks with emergent abilities. However, they face inherent limitations, such as an inability to access up-to-date information, utilize external tools, or perform precise mathematical reasoning. In this paper, we introduce Chameleon, a plug-and-play compositional reasoning framework that augments LLMs to help address these challenges. Chameleon synthesizes programs to compose various tools, including LLM models, off-the-shelf vision models, web search engines, Python functions, and rule-based modules tailored to user interests. Built on top of an LLM as a natural language planner, Chameleon infers the appropriate sequence of tools to compose and execute in order to generate a final response. We showcase the adaptability and effectiveness of Chameleon on two tasks: ScienceQA and TabMWP. Notably, Chameleon with GPT-4 achieves an 86.54% accuracy on ScienceQA, significantly improving upon the best published few-shot model by 11.37%; using GPT-4 as the underlying LLM, Chameleon achieves a 17.8% increase over the state-of-the-art model, leading to a 98.78% overall accuracy on TabMWP. Further studies suggest that using GPT-4 as a plan- ner exhibits more consistent and rational tool selection and is able to infer potential constraints given the instructions, compared to other LLMs like ChatGPT.\n",
    "    \n",
    "* [Consistency Models](https://arxiv.org/pdf/2303.01469.pdf)\n",
    "    - Abstract: Diffusion models have made significant break- throughs in image, audio, and video generation, but they depend on an iterative generation process that causes slow sampling speed and caps their potential for real-time applications. To overcome this limitation, we propose consistency models, a new family of generative models that achieve high sample quality without adversarial training. They support fast one-step generation by design, while still allowing for few-step sampling to trade compute for sample quality. They also support zero-shot data editing, like image inpainting, col- orization, and super-resolution, without requir- ing explicit training on these tasks. Consistency models can be trained either as a way to distill pre-trained diffusion models, or as standalone gen- erative models. Through extensive experiments, we demonstrate that they outperform existing dis- tillation techniques for diffusion models in one- and few-step generation. For example, we achieve the new state-of-the-art FID of 3.55 on CIFAR- 10 and 6.20 on ImageNet 64 ˆ 64 for one-step generation. When trained as standalone genera- tive models, consistency models also outperform single-step, non-adversarial generative models on standard benchmarks like CIFAR-10, ImageNet 64 ˆ 64 and LSUN 256 ˆ 256.\n",
    "    - Ilya Sutskever is one of the authors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
