{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d551ee",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb9371",
   "metadata": {},
   "source": [
    "## Torch Module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc7f3c",
   "metadata": {},
   "source": [
    "### For reproducibility: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c1e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208b962",
   "metadata": {},
   "source": [
    "## Prepare Data:\n",
    "### Get the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445541d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(ROOT,\n",
    "                              train=True,\n",
    "                              download=True,\n",
    "                              transform=train_transforms)\n",
    "\n",
    "test_data = datasets.CIFAR10(ROOT,\n",
    "                             train=False,\n",
    "                             download=True,\n",
    "                             transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b35eb",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "sometimes you need to apply some transforms to your dataset, when that happens you can do this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.data'\n",
    "\n",
    "train_data = datasets.CIFAR10(root=ROOT,\n",
    "                              train=True,\n",
    "                              download=True)\n",
    "\n",
    "means = train_data.data.mean(axis=(0, 1, 2)) / 255\n",
    "stds = train_data.data.std(axis=(0, 1, 2)) / 255\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')\n",
    "\n",
    "\n",
    "# The transformation\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(32, padding=2),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means,\n",
    "                                                std=stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means,\n",
    "                                                std=stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b1644",
   "metadata": {},
   "source": [
    "### Create a Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0617d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data,\n",
    "                                           [n_train_examples, n_valid_\n",
    "                                \n",
    "# and ensure our validation set uses the test transform\n",
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms\n",
    "\n",
    "# printing the len\n",
    "\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0bd00",
   "metadata": {},
   "source": [
    "## Become one with your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff105dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, classes, normalize=False):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image_min = image.min()\n",
    "            image_max = image.max()\n",
    "            image.clamp_(min=image_min, max=image_max)\n",
    "            image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        ax.set_title(classes[labels[i]])\n",
    "        ax.axis('off')\n",
    "\n",
    "## Visualization\n",
    "\n",
    "N_IMAGES = 25\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                       [train_data[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = test_data.classes\n",
    "\n",
    "plot_images(images, labels, classes)\n",
    "\n",
    "plot_images(images, labels, classes, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832550fc",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min=image_min, max=image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def plot_filter(images, filter, normalize=True):\n",
    "\n",
    "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
    "    filter = torch.FloatTensor(filter).unsqueeze(0).unsqueeze(0).cpu()\n",
    "    filter = filter.repeat(3, 3, 1, 1)\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "\n",
    "    filtered_images = F.conv2d(images, filter)\n",
    "\n",
    "    images = images.permute(0, 2, 3, 1)\n",
    "    filtered_images = filtered_images.permute(0, 2, 3, 1)\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 5))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(2, n_images, i+1)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        image = filtered_images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(2, n_images, n_images+i+1)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title('Filtered')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21a996",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897486d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6524ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 10\n",
    "\n",
    "model = AlexNet(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a320c350",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676b996",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28f3f8",
   "metadata": {},
   "source": [
    "### Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dafb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f3c1b",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7167cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "        torch.save(model.state_dict(), 'init_params.pt')\n",
    "\n",
    "    def range_test(self, iterator, end_lr=10, num_iter=100,\n",
    "                   smooth_f=0.05, diverge_th=5):\n",
    "\n",
    "        lrs = []\n",
    "        losses = []\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "\n",
    "        iterator = IteratorWrapper(iterator)\n",
    "\n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            loss = self._train_batch(iterator)\n",
    "\n",
    "            lrs.append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "            # update lr\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            if iteration > 0:\n",
    "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
    "\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "            if loss > diverge_th * best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "\n",
    "        # reset model to initial parameters\n",
    "        model.load_state_dict(torch.load('init_params.pt'))\n",
    "\n",
    "        return lrs, losses\n",
    "\n",
    "    def _train_batch(self, iterator):\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        x, y = iterator.get_batch()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        y_pred, _ = self.model(x)\n",
    "\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r\n",
    "                for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "class IteratorWrapper:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self._iterator = iter(iterator)\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            inputs, labels = next(self._iterator)\n",
    "        except StopIteration:\n",
    "            self._iterator = iter(self.iterator)\n",
    "            inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def get_batch(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
